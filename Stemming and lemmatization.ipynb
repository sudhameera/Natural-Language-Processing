{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035d42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302922ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca91c25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "adjustable | adjust\n",
      "rafting | raft\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "words = ['eating', 'eats','eat','ate','adjustable','rafting','ability','meeting']\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\",stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ee556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | eat\n",
      "adjuatable | adjuatable\n",
      "rafting | raft\n",
      "ability | ability\n",
      "meeting | meeting\n",
      "better | well\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"eating eats eat ate adjuatable rafting ability meeting better\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\",word.lemma_\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266b8fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5edda800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | bro\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brah\n",
      ", | ,\n",
      "do | do\n",
      "nt | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, dont say no! I am exhausted\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\",word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b21515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar=nlp.get_pipe('attribute_ruler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12de7b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "nt | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, dont say no! I am exhausted\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\",word.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782dcd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | like\n",
      "children | children\n",
      "whom | whom\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "#using stemming in nltk\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "for word in lst_words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406d4f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | likely\n",
      "children | child\n",
      "who | who\n",
      "good | good\n",
      "ate | eat\n",
      "fishing | fishing\n"
     ]
    }
   ],
   "source": [
    "#using lemmatization in spacy\n",
    "\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18ec254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L | l\n",
      "a | a\n",
      "t | t\n",
      "h | h\n",
      "a | a\n",
      "  |  \n",
      "i | i\n",
      "s | s\n",
      "  |  \n",
      "v | v\n",
      "e | e\n",
      "r | r\n",
      "y | y\n",
      "  |  \n",
      "m | m\n",
      "u | u\n",
      "l | l\n",
      "t | t\n",
      "i | i\n",
      "  |  \n",
      "t | t\n",
      "a | a\n",
      "l | l\n",
      "e | e\n",
      "n | n\n",
      "t | t\n",
      "e | e\n",
      "d | d\n",
      "  |  \n",
      "g | g\n",
      "i | i\n",
      "r | r\n",
      "l | l\n",
      ". | .\n",
      "S | s\n",
      "h | h\n",
      "e | e\n",
      "  |  \n",
      "i | i\n",
      "s | s\n",
      "  |  \n",
      "g | g\n",
      "o | o\n",
      "o | o\n",
      "d | d\n",
      "  |  \n",
      "a | a\n",
      "t | t\n",
      "  |  \n",
      "m | m\n",
      "a | a\n",
      "n | n\n",
      "y | y\n",
      "  |  \n",
      "s | s\n",
      "k | k\n",
      "i | i\n",
      "l | l\n",
      "l | l\n",
      "s | s\n",
      "  |  \n",
      "l | l\n",
      "i | i\n",
      "k | k\n",
      "e | e\n",
      "  |  \n",
      "d | d\n",
      "a | a\n",
      "n | n\n",
      "c | c\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      ", | ,\n",
      "  |  \n",
      "r | r\n",
      "u | u\n",
      "n | n\n",
      "n | n\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      ", | ,\n",
      "  |  \n",
      "s | s\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      ", | ,\n",
      "  |  \n",
      "p | p\n",
      "l | l\n",
      "a | a\n",
      "y | y\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      ". | .\n",
      "S | s\n",
      "h | h\n",
      "e | e\n",
      "  |  \n",
      "a | a\n",
      "l | l\n",
      "s | s\n",
      "o | o\n",
      "  |  \n",
      "l | l\n",
      "i | i\n",
      "k | k\n",
      "e | e\n",
      "s | s\n",
      "  |  \n",
      "e | e\n",
      "a | a\n",
      "t | t\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      "  |  \n",
      "P | p\n",
      "a | a\n",
      "v | v\n",
      "  |  \n",
      "B | b\n",
      "h | h\n",
      "a | a\n",
      "g | g\n",
      "i | i\n",
      ". | .\n",
      "  |  \n",
      "s | s\n",
      "h | h\n",
      "e | e\n",
      "  |  \n",
      "h | h\n",
      "a | a\n",
      "s | s\n",
      "  |  \n",
      "a | a\n",
      "  |  \n",
      "\n",
      " | \n",
      "\n",
      "h | h\n",
      "a | a\n",
      "b | b\n",
      "i | i\n",
      "t | t\n",
      "  |  \n",
      "o | o\n",
      "f | f\n",
      "  |  \n",
      "f | f\n",
      "i | i\n",
      "s | s\n",
      "h | h\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      "  |  \n",
      "a | a\n",
      "n | n\n",
      "d | d\n",
      "  |  \n",
      "s | s\n",
      "w | w\n",
      "i | i\n",
      "m | m\n",
      "m | m\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      "  |  \n",
      "t | t\n",
      "o | o\n",
      "o | o\n",
      ". | .\n",
      "B | b\n",
      "e | e\n",
      "s | s\n",
      "i | i\n",
      "d | d\n",
      "e | e\n",
      "s | s\n",
      "  |  \n",
      "a | a\n",
      "l | l\n",
      "l | l\n",
      "  |  \n",
      "t | t\n",
      "h | h\n",
      "i | i\n",
      "s | s\n",
      ", | ,\n",
      "  |  \n",
      "s | s\n",
      "h | h\n",
      "e | e\n",
      "  |  \n",
      "i | i\n",
      "s | s\n",
      "  |  \n",
      "a | a\n",
      "  |  \n",
      "w | w\n",
      "o | o\n",
      "n | n\n",
      "d | d\n",
      "e | e\n",
      "r | r\n",
      "f | f\n",
      "u | u\n",
      "l | l\n",
      "  |  \n",
      "a | a\n",
      "t | t\n",
      "  |  \n",
      "c | c\n",
      "o | o\n",
      "o | o\n",
      "k | k\n",
      "i | i\n",
      "n | n\n",
      "g | g\n",
      "  |  \n",
      "t | t\n",
      "o | o\n",
      "o | o\n",
      ". | .\n",
      "\n",
      " | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "#using stemming in nltk\n",
    "\n",
    "#step1: Word tokenizing\n",
    "\n",
    "#step2: getting the base form for each token using stemmer\n",
    "\n",
    "for word in text:\n",
    "    print(word, \"|\" ,stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7953752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1d2acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
     ]
    }
   ],
   "source": [
    "#using stemming in nltk\n",
    "\n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "\n",
    "#step1: Word tokenizing\n",
    "all_word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "#step2: getting the base form for each token using stemmer\n",
    "all_base_words = []\n",
    "\n",
    "for token in all_word_tokens:\n",
    "    base_form = stemmer.stem(token)\n",
    "    all_base_words.append(base_form)\n",
    "   \n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "\n",
    "final_base_words = \" \".join(all_base_words)\n",
    "print(final_base_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2a821d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
      " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using lemmatisation in spacy\n",
    "\n",
    "#step1: Creating the object for the given text\n",
    "text =\"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "doc= nlp(text)\n",
    "\n",
    "#step2: getting the base form for each token using spacy 'lemma_'\n",
    "\n",
    "all_base_words=[]\n",
    "for word in doc:\n",
    "    base_word = word.lemma_\n",
    "    all_base_words.append(base_word)\n",
    "    \n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "final_base_text = ' '.join(all_base_words)\n",
    "print(final_base_text)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dae933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon | PROPN | proper noun\n",
      "flew | VERB | verb\n",
      "to | ADP | adposition\n",
      "mars | NOUN | noun\n",
      "yesterday | NOUN | noun\n",
      ", | PUNCT | punctuation\n",
      "he | PRON | pronoun\n",
      "carried | VERB | verb\n",
      "briyani | ADJ | adjective\n",
      "masala | NOUN | noun\n",
      "with | ADP | adposition\n",
      "him | PRON | pronoun\n"
     ]
    }
   ],
   "source": [
    "doc= nlp(\"Elon flew to mars yesterday, he carried briyani masala with him\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.pos_,\"|\" ,spacy.explain(word.pos_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3356da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a | DET | determiner\n",
      "person | NOUN | noun\n",
      "Elon | PROPN | proper noun\n",
      "flew | VERB | verb\n",
      "to | ADP | adposition\n",
      "mars | NOUN | noun\n",
      "yesterday | NOUN | noun\n",
      ", | PUNCT | punctuation\n",
      "he | PRON | pronoun\n",
      "carried | VERB | verb\n",
      "briyani | ADJ | adjective\n",
      "masala | NOUN | noun\n",
      "with | ADP | adposition\n",
      "him | PRON | pronoun\n"
     ]
    }
   ],
   "source": [
    "doc= nlp(\"a person Elon flew to mars yesterday, he carried briyani masala with him\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.pos_,\"|\" ,spacy.explain(word.pos_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20f1c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow | INTJ | interjection\n",
      "! | PUNCT | punctuation\n",
      "Dr. | PROPN | proper noun\n",
      "Strange | PROPN | proper noun\n",
      "made | VERB | verb\n",
      "256 | NUM | numeral\n",
      "billion | NUM | numeral\n",
      "$ | SYM | symbol\n",
      "on | ADP | adposition\n",
      "the | DET | determiner\n",
      "very | ADV | adverb\n",
      "first | ADJ | adjective\n",
      "day | NOUN | noun\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"wow! Dr.Strange made 256 billion $ on the very first day\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.pos_,\"|\", \n",
    "          spacy.explain(word.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04348fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow | INTJ | interjection | UH | interjection\n",
      "! | PUNCT | punctuation | . | punctuation mark, sentence closer\n",
      "Dr. | PROPN | proper noun | NNP | noun, proper singular\n",
      "Strange | PROPN | proper noun | NNP | noun, proper singular\n",
      "made | VERB | verb | VBD | verb, past tense\n",
      "256 | NUM | numeral | CD | cardinal number\n",
      "billion | NUM | numeral | CD | cardinal number\n",
      "$ | SYM | symbol | $ | symbol, currency\n",
      "on | ADP | adposition | IN | conjunction, subordinating or preposition\n",
      "the | DET | determiner | DT | determiner\n",
      "very | ADV | adverb | RB | adverb\n",
      "first | ADJ | adjective | JJ | adjective (English), other noun-modifier (Chinese)\n",
      "day | NOUN | noun | NN | noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"wow! Dr.Strange made 256 billion $ on the very first day\")\n",
    "\n",
    "for word in doc:\n",
    "    print(word, \"|\", word.pos_,\"|\", \n",
    "          spacy.explain(word.pos_),\"|\",word.tag_,\"|\",spacy.explain(word.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "952e43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quits | VBZ | verb, 3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "doc= nlp(\"he quits the job\")\n",
    "\n",
    "doc[1]\n",
    "print(doc[1],\"|\",doc[1].tag_,\"|\",spacy.explain(doc[1].tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03bbd387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quit | VBD | verb, past tense\n"
     ]
    }
   ],
   "source": [
    "doc= nlp(\"he quit the job\")\n",
    "\n",
    "doc[1]\n",
    "print(doc[1],\"|\",doc[1].tag_,\"|\",spacy.explain(doc[1].tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d36925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For | IN | conjunction, subordinating or preposition\n",
      "the | DT | determiner\n",
      "third | JJ | adjective (English), other noun-modifier (Chinese)\n",
      "quarter | NN | noun, singular or mass\n",
      ", | , | punctuation mark, comma\n",
      "the | DT | determiner\n",
      "company | NN | noun, singular or mass\n",
      "reported | VBD | verb, past tense\n",
      "advertising | NN | noun, singular or mass\n",
      "revenue | NN | noun, singular or mass\n",
      "of | IN | conjunction, subordinating or preposition\n",
      "$ | $ | symbol, currency\n",
      "59.65 | CD | cardinal number\n",
      "billion | CD | cardinal number\n",
      ", | , | punctuation mark, comma\n",
      "up | RB | adverb\n",
      "from | IN | conjunction, subordinating or preposition\n",
      "$ | $ | symbol, currency\n",
      "54.48 | CD | cardinal number\n",
      "billion | CD | cardinal number\n",
      "a | DT | determiner\n",
      "year | NN | noun, singular or mass\n",
      "ago | RB | adverb\n",
      ". | . | punctuation mark, sentence closer\n",
      "YouTube | NNP | noun, proper singular\n",
      "advertising | NN | noun, singular or mass\n",
      "revenue | NN | noun, singular or mass\n",
      "beat | NN | noun, singular or mass\n",
      "analyst | NN | noun, singular or mass\n",
      "expectations | NNS | noun, plural\n",
      ", | , | punctuation mark, comma\n",
      "reporting | VBG | verb, gerund or present participle\n",
      "$ | $ | symbol, currency\n",
      "7.95 | CD | cardinal number\n",
      "billion | CD | cardinal number\n",
      ". | . | punctuation mark, sentence closer\n",
      "In | IN | conjunction, subordinating or preposition\n",
      "a | DT | determiner\n",
      "call | NN | noun, singular or mass\n",
      "with | IN | conjunction, subordinating or preposition\n",
      "investors | NNS | noun, plural\n",
      ", | , | punctuation mark, comma\n",
      "Alphabet | NNP | noun, proper singular\n",
      "CEO | NNP | noun, proper singular\n",
      "Sundar | NNP | noun, proper singular\n",
      "Pichai | NNP | noun, proper singular\n",
      "said | VBD | verb, past tense\n",
      "Shorts | NNS | noun, plural\n",
      ", | , | punctuation mark, comma\n",
      "YouTube | NNP | noun, proper singular\n",
      "’s | POS | possessive ending\n",
      "TikTok | JJ | adjective (English), other noun-modifier (Chinese)\n",
      "competitor | NN | noun, singular or mass\n",
      ", | , | punctuation mark, comma\n",
      "now | RB | adverb\n",
      "has | VBZ | verb, 3rd person singular present\n",
      "70 | CD | cardinal number\n",
      "billion | CD | cardinal number\n",
      "daily | JJ | adjective (English), other noun-modifier (Chinese)\n",
      "views | NNS | noun, plural\n",
      ", | , | punctuation mark, comma\n",
      "up | RB | adverb\n",
      "from | IN | conjunction, subordinating or preposition\n",
      "the | DT | determiner\n",
      "more | JJR | adjective, comparative\n",
      "than | IN | conjunction, subordinating or preposition\n",
      "50 | CD | cardinal number\n",
      "billion | CD | cardinal number\n",
      "daily | JJ | adjective (English), other noun-modifier (Chinese)\n",
      "views | NNS | noun, plural\n",
      "at | IN | conjunction, subordinating or preposition\n",
      "the | DT | determiner\n",
      "beginning | NN | noun, singular or mass\n",
      "of | IN | conjunction, subordinating or preposition\n",
      "the | DT | determiner\n",
      "year | NN | noun, singular or mass\n",
      ". | . | punctuation mark, sentence closer\n",
      "\n",
      "\n",
      " | _SP | whitespace\n",
      "Cloud | NNP | noun, proper singular\n",
      "revenue | NN | noun, singular or mass\n",
      "came | VBD | verb, past tense\n",
      "in | RP | adverb, particle\n",
      "below | IN | conjunction, subordinating or preposition\n",
      "estimates | NNS | noun, plural\n",
      "at | IN | conjunction, subordinating or preposition\n",
      "$ | $ | symbol, currency\n",
      "8.41 | CD | cardinal number\n",
      "billion | CD | cardinal number\n",
      ", | , | punctuation mark, comma\n",
      "missing | VBG | verb, gerund or present participle\n",
      "the | DT | determiner\n",
      "mark | NN | noun, singular or mass\n",
      "by | IN | conjunction, subordinating or preposition\n",
      "more | JJR | adjective, comparative\n",
      "than | IN | conjunction, subordinating or preposition\n",
      "$ | $ | symbol, currency\n",
      "20 | CD | cardinal number\n",
      "million | CD | cardinal number\n",
      ". | . | punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "#counting No of Noun, verb etc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "earnings_report = '''For the third quarter, the company reported advertising revenue of $59.65 billion, up from $54.48 billion a year ago. YouTube advertising revenue beat analyst expectations, reporting $7.95 billion. In a call with investors, Alphabet CEO Sundar Pichai said Shorts, YouTube’s TikTok competitor, now has 70 billion daily views, up from the more than 50 billion daily views at the beginning of the year.\n",
    "\n",
    "Cloud revenue came in below estimates at $8.41 billion, missing the mark by more than $20 million.'''\n",
    "\n",
    "doc = nlp (earnings_report)\n",
    "\n",
    "for word in doc:\n",
    "    print(word,\"|\",word.tag_,\"|\",spacy.explain(word.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12f05ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", | PUNCT | punctuation\n",
      ", | PUNCT | punctuation\n",
      ". | PUNCT | punctuation\n",
      ", | PUNCT | punctuation\n",
      ". | PUNCT | punctuation\n",
      ", | PUNCT | punctuation\n",
      ", | PUNCT | punctuation\n",
      ", | PUNCT | punctuation\n",
      ", | PUNCT | punctuation\n",
      ". | PUNCT | punctuation\n",
      "\n",
      "\n",
      " | SPACE | space\n",
      ", | PUNCT | punctuation\n",
      ". | PUNCT | punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp (earnings_report)\n",
    "\n",
    "for word in doc:\n",
    "    if word.pos_ in [\"SPACE\",\"X\",\"PUNCT\"]:\n",
    "        print(word,\"|\", word.pos_,\"|\" ,spacy.explain(word.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e2b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words=[]\n",
    "for word in doc:\n",
    "    if word.pos_ not in [\"SPACE\",\"X\",\"PUNCT\"]:\n",
    "        filtered_words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca45128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[For,\n",
       " the,\n",
       " third,\n",
       " quarter,\n",
       " the,\n",
       " company,\n",
       " reported,\n",
       " advertising,\n",
       " revenue,\n",
       " of,\n",
       " $,\n",
       " 59.65,\n",
       " billion,\n",
       " up,\n",
       " from,\n",
       " $,\n",
       " 54.48,\n",
       " billion,\n",
       " a,\n",
       " year,\n",
       " ago,\n",
       " YouTube,\n",
       " advertising,\n",
       " revenue,\n",
       " beat,\n",
       " analyst,\n",
       " expectations,\n",
       " reporting,\n",
       " $,\n",
       " 7.95,\n",
       " billion,\n",
       " In,\n",
       " a,\n",
       " call,\n",
       " with,\n",
       " investors,\n",
       " Alphabet,\n",
       " CEO,\n",
       " Sundar,\n",
       " Pichai,\n",
       " said,\n",
       " Shorts,\n",
       " YouTube,\n",
       " ’s,\n",
       " TikTok,\n",
       " competitor,\n",
       " now,\n",
       " has,\n",
       " 70,\n",
       " billion,\n",
       " daily,\n",
       " views,\n",
       " up,\n",
       " from,\n",
       " the,\n",
       " more,\n",
       " than,\n",
       " 50,\n",
       " billion,\n",
       " daily,\n",
       " views,\n",
       " at,\n",
       " the,\n",
       " beginning,\n",
       " of,\n",
       " the,\n",
       " year,\n",
       " Cloud,\n",
       " revenue,\n",
       " came,\n",
       " in,\n",
       " below,\n",
       " estimates,\n",
       " at,\n",
       " $,\n",
       " 8.41,\n",
       " billion,\n",
       " missing,\n",
       " the,\n",
       " mark,\n",
       " by,\n",
       " more,\n",
       " than,\n",
       " $,\n",
       " 20,\n",
       " million]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e2e8125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{85: 14,\n",
       " 90: 8,\n",
       " 84: 6,\n",
       " 92: 21,\n",
       " 97: 12,\n",
       " 100: 6,\n",
       " 99: 5,\n",
       " 93: 14,\n",
       " 86: 4,\n",
       " 96: 7,\n",
       " 94: 1,\n",
       " 103: 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e964b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADP'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " doc.vocab[85].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9800d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADP | 14\n",
      "DET | 8\n",
      "ADJ | 6\n",
      "NOUN | 21\n",
      "PUNCT | 12\n",
      "VERB | 6\n",
      "SYM | 5\n",
      "NUM | 14\n",
      "ADV | 4\n",
      "PROPN | 7\n",
      "PART | 1\n",
      "SPACE | 1\n"
     ]
    }
   ],
   "source": [
    "for k , v in count.items():\n",
    "    print(word.vocab[k].text,\"|\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b48578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inflation rose again in April, continuing a climb that has pushed consumers to the brink and is threatening the economic expansion, the Bureau of Labor Statistics reported Wednesday.\\n\\nThe consumer price index, a broad-based measure of prices for goods and services, increased 8.3% from a year ago, higher than the Dow Jones estimate for an 8.1% gain. That represented a slight ease from Marchâ€™s peak but was still close to the highest level since the summer of 1982.\\n\\nRemoving volatile food and energy prices, so-called core CPI still rose 6.2%, against expectations for a 6% gain, clouding hopes that inflation had peaked in March.\\n\\nThe month-over-month gains also were higher than expectations â€” 0.3% on headline CPI versus the 0.2% estimate and a 0.6% increase for core, against the outlook for a 0.4% gain.\\n\\nThe price gains also meant that workers continued to lose ground. Real wages adjusted for inflation decreased 0.1% on the month despite a nominal increase of 0.3% in average hourly earnings. Over the past year, real earnings have dropped 2.6% even though average hourly earnings are up 5.5%.\\n\\nInflation has been the single biggest threat to a recovery that began early in the Covid pandemic and saw the economy in 2021 stage its biggest single-year growth level since 1984. Rising prices at the pump and in grocery stores have been one problem, but inflation has spread beyond those two areas into housing, auto sales and a host of other areas.\\n\\nFederal Reserve officials have responded to the problem with two interest rate hikes so far this year and pledges of more until inflation comes down to the central bankâ€™s 2% goal. However, Wednesdayâ€™s data shows that the Fed has a big job ahead.\\n\\nCredits: cnbc.com'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open (\"news_story.txt\")  as f:\n",
    "    news_text=f.read()\n",
    "news_text    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a93d5",
   "metadata": {},
   "source": [
    "# Extract NOUN and NUM tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82247088",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(news_text)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d68e6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_count=[]\n",
    "num_tokens=[]\n",
    "\n",
    "for word in doc:\n",
    "    if word.pos_==\"NOUN\":\n",
    "        noun_count.append(word)\n",
    "    elif word.pos_==\"NUM\":\n",
    "        num_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c745269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Inflation,\n",
       " climb,\n",
       " consumers,\n",
       " brink,\n",
       " expansion,\n",
       " consumer,\n",
       " price,\n",
       " index,\n",
       " measure,\n",
       " prices,\n",
       " goods,\n",
       " services,\n",
       " %,\n",
       " year,\n",
       " estimate,\n",
       " %,\n",
       " gain,\n",
       " ease,\n",
       " Marchâ€,\n",
       " ™,\n",
       " peak,\n",
       " level,\n",
       " summer,\n",
       " food,\n",
       " energy,\n",
       " prices,\n",
       " core,\n",
       " %,\n",
       " expectations,\n",
       " %,\n",
       " gain,\n",
       " hopes,\n",
       " inflation,\n",
       " month,\n",
       " month,\n",
       " gains,\n",
       " expectations,\n",
       " %,\n",
       " headline,\n",
       " %,\n",
       " estimate,\n",
       " %,\n",
       " increase,\n",
       " core,\n",
       " outlook,\n",
       " %,\n",
       " gain,\n",
       " price,\n",
       " gains,\n",
       " workers,\n",
       " ground,\n",
       " wages,\n",
       " inflation,\n",
       " %,\n",
       " month,\n",
       " increase,\n",
       " %,\n",
       " earnings,\n",
       " year,\n",
       " earnings,\n",
       " %,\n",
       " earnings,\n",
       " %,\n",
       " Inflation,\n",
       " threat,\n",
       " recovery,\n",
       " pandemic,\n",
       " economy,\n",
       " stage,\n",
       " year,\n",
       " growth,\n",
       " level,\n",
       " prices,\n",
       " pump,\n",
       " grocery,\n",
       " stores,\n",
       " problem,\n",
       " inflation,\n",
       " areas,\n",
       " housing,\n",
       " auto,\n",
       " sales,\n",
       " host,\n",
       " areas,\n",
       " officials,\n",
       " problem,\n",
       " interest,\n",
       " rate,\n",
       " hikes,\n",
       " year,\n",
       " pledges,\n",
       " inflation,\n",
       " %,\n",
       " goal,\n",
       " ™,\n",
       " data,\n",
       " job,\n",
       " Credits]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55ccc6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.3,\n",
       " 8.1,\n",
       " 1982,\n",
       " 6.2,\n",
       " 6,\n",
       " â€,\n",
       " 0.3,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.1,\n",
       " 0.3,\n",
       " 2.6,\n",
       " 5.5,\n",
       " 2021,\n",
       " 1984,\n",
       " one,\n",
       " two,\n",
       " two,\n",
       " 2]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c814f2e",
   "metadata": {},
   "source": [
    "# Print a count of all POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ecfe4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{92: 98,\n",
       " 100: 27,\n",
       " 86: 15,\n",
       " 85: 39,\n",
       " 96: 17,\n",
       " 97: 32,\n",
       " 90: 34,\n",
       " 95: 4,\n",
       " 87: 13,\n",
       " 89: 10,\n",
       " 84: 23,\n",
       " 103: 7,\n",
       " 93: 20,\n",
       " 94: 4,\n",
       " 98: 8,\n",
       " 101: 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0a90c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN 98\n",
      "VERB 27\n",
      "ADV 15\n",
      "ADP 39\n",
      "PROPN 17\n",
      "PUNCT 32\n",
      "DET 34\n",
      "PRON 4\n",
      "AUX 13\n",
      "CCONJ 10\n",
      "ADJ 23\n",
      "SPACE 7\n",
      "NUM 20\n",
      "PART 4\n",
      "SCONJ 8\n",
      "X 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in count.items():\n",
    "    print(word.vocab[k].text,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd387037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
